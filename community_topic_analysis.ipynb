{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import random as ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_size=20\n",
    "label_size=18\n",
    "legend_size=16\n",
    "ticklabel_size=14\n",
    "text_size=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"husl\")\n",
    "MachineLearning_color=(214/255.,95/255.,95/255.)\n",
    "datascience_color=(72/255.,120/255.,207/255.)\n",
    "compsci_color=(207/255., 120/255., 72/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory='/home/preston/Desktop/Programming/datasci/projects/blog_finder/data/reddit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file and store all submissions, titles into a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_directory='/home/preston/Desktop/Programming/datasci/projects/blog_finder/data/reddit/'\n",
    "se_directory='/home/preston/Desktop/Programming/datasci/projects/blog_finder/data/stackexchange/'\n",
    "r_MachineLearning_filename='MachineLearning'\n",
    "r_datascience_filename='datascience'\n",
    "se_datascience_filename='datascience_questions'\n",
    "r_statistics_filename='statistics'\n",
    "r_compsci_filename='compsci'\n",
    "se_stackoverflow_filename='stackoverflow_questions'\n",
    "r_physics_filename='physics'\n",
    "r_Cooking_filename='Cooking'\n",
    "r_food_filename='food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_MachineLearning_filehandle=open(r_directory+r_MachineLearning_filename)\n",
    "r_datascience_filehandle=open(r_directory+r_datascience_filename)\n",
    "se_datascience_filehandle=open(se_directory+se_datascience_filename)\n",
    "r_statistics_filehandle=open(r_directory+r_statistics_filename)\n",
    "r_compsci_filehandle=open(r_directory+r_compsci_filename)\n",
    "se_stackoverflow_filehandle=open(se_directory+se_stackoverflow_filename)\n",
    "r_physics_filehandle=open(r_directory+r_physics_filename)\n",
    "r_Cooking_filehandle=open(r_directory+r_Cooking_filename)\n",
    "r_food_filehandle=open(r_directory+r_food_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['name', 'title']\n",
    "r_MachineLearning_df=pd.DataFrame(columns=columns)\n",
    "r_datascience_df=pd.DataFrame(columns=columns)\n",
    "se_datascience_df=pd.DataFrame(columns=columns)\n",
    "r_statistics_df=pd.DataFrame(columns=columns)\n",
    "r_compsci_df=pd.DataFrame(columns=columns)\n",
    "se_stackoverflow_df=pd.DataFrame(columns=columns)\n",
    "r_physics_df=pd.DataFrame(columns=columns)\n",
    "r_Cooking_df=pd.DataFrame(columns=columns)\n",
    "r_food_df=pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=r_MachineLearning_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    if line_json['name'].split('_')[0]=='t3':\n",
    "        r_MachineLearning_df.loc[len(r_MachineLearning_df)]=[line_json['name'], line_json['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line = json.loads(r_datascience_filehandle.readline())\n",
    "    if line['name'].split('_')[0]=='t3':\n",
    "        r_datascience_df.loc[len(r_datascience_df)]=[line['name'], line['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=se_datascience_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    for item in line_json['items']:\n",
    "        se_datascience_df.loc[len(se_datascience_df)]=[item['question_id'], item['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=r_statistics_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    if line_json['name'].split('_')[0]=='t3':\n",
    "        r_statistics_df.loc[len(r_statistics_df)]=[line_json['name'], line_json['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line = json.loads(r_compsci_filehandle.readline())\n",
    "    if line['name'].split('_')[0]=='t3':\n",
    "        r_compsci_df.loc[len(r_compsci_df)]=[line['name'], line['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "i=0\n",
    "while line:\n",
    "    if i%100==0:\n",
    "        print i\n",
    "    line=se_stackoverflow_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    for item in line_json['items']:\n",
    "        se_stackoverflow_df.loc[len(se_stackoverflow_df)]=[item['question_id'], item['title']]\n",
    "        \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=r_physics_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    if line_json['name'].split('_')[0]=='t3':\n",
    "        r_physics_df.loc[len(r_physics_df)]=[line_json['name'], line_json['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=r_Cooking_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    if line_json['name'].split('_')[0]=='t3':\n",
    "        r_Cooking_df.loc[len(r_Cooking_df)]=[line_json['name'], line_json['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line=' '\n",
    "while line:\n",
    "    line=r_food_filehandle.readline()\n",
    "    line_json=json.loads(line)\n",
    "    \n",
    "    if line_json['name'].split('_')[0]=='t3':\n",
    "        r_food_df.loc[len(r_food_df)]=[line_json['name'], line_json['title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase all letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [r_MachineLearning_df, r_datascience_df, se_datascience_df, r_statistics_df, r_compsci_df, se_stackoverflow_df,\\\n",
    "           r_physics_df, r_Cooking_df, r_food_df]:\n",
    "    df['title']=df['title'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all non-words\n",
    "- 0-9\n",
    "- !, @, #, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [r_MachineLearning_df, r_datascience_df, se_datascience_df, r_statistics_df, r_compsci_df, se_stackoverflow_df,\\\n",
    "           r_physics_df, r_Cooking_df, r_food_df]:\n",
    "    df['title']=df['title'].map(lambda x: ' '.join([word for word in x.split(' ') if word not in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary from submission titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_MachineLearning_document=''\n",
    "r_datascience_document=''\n",
    "se_datascience_document=''\n",
    "r_statistics_document=''\n",
    "r_compsci_document=''\n",
    "se_stackoverflow_document=''\n",
    "r_physics_document=''\n",
    "r_Cooking_document=''\n",
    "r_food_document=''\n",
    "\n",
    "for title in r_MachineLearning_df['title'].values:\n",
    "    r_MachineLearning_document+=title+' '\n",
    "    \n",
    "for title in r_datascience_df['title'].values:\n",
    "    r_datascience_document+=title+' '\n",
    "    \n",
    "for title in se_datascience_df['title'].values:\n",
    "    se_datascience_document+=title+' '\n",
    "    \n",
    "for title in r_statistics_df['title'].values:\n",
    "    r_statistics_document+=title+' '\n",
    "    \n",
    "for title in r_compsci_df['title'].values:\n",
    "    r_compsci_document+=title+' '\n",
    "    \n",
    "for title in se_stackoverflow_df['title'].values:\n",
    "    se_stackoverflow_document+=title+' '\n",
    "    \n",
    "for title in r_physics_df['title'].values:\n",
    "    r_physics_document+=title+' '\n",
    "    \n",
    "for title in r_Cooking_df['title'].values:\n",
    "    r_Cooking_document+=title+' '\n",
    "    \n",
    "for title in r_food_df['title'].values:\n",
    "    r_food_document+=title+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_MachineLearning_word_list=filter(None,r_MachineLearning_document.split(' '))\n",
    "r_datascience_word_list=filter(None,r_datascience_document.split(' '))\n",
    "se_datascience_word_list=filter(None,se_datascience_document.split(' '))\n",
    "r_statistics_word_list=filter(None,r_statistics_document.split(' '))\n",
    "r_compsci_word_list=filter(None,r_compsci_document.split(' '))\n",
    "se_stackoverflow_word_list=filter(None,se_stackoverflow_document.split(' '))\n",
    "r_physics_word_list=filter(None,r_physics_document.split(' '))\n",
    "r_Cooking_word_list=filter(None,r_Cooking_document.split(' '))\n",
    "r_food_word_list=filter(None,r_food_document.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_MachineLearning_word_dict={}\n",
    "r_datascience_word_dict={}\n",
    "se_datascience_word_dict={}\n",
    "r_statistics_word_dict={}\n",
    "r_compsci_word_dict={}\n",
    "se_stackoverflow_word_dict={}\n",
    "r_physics_word_dict={}\n",
    "r_Cooking_word_dict={}\n",
    "r_food_word_dict={}\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "for word in r_MachineLearning_word_list:\n",
    "    if word in r_MachineLearning_word_dict:\n",
    "        r_MachineLearning_word_dict[word]+=1\n",
    "    else:\n",
    "        r_MachineLearning_word_dict[word]=0\n",
    "        \n",
    "for key in r_MachineLearning_word_dict:\n",
    "    r_MachineLearning_word_dict[key]=1.*r_MachineLearning_word_dict[key]/len(r_MachineLearning_word_list)\n",
    "\n",
    "################################################################################################################    \n",
    "    \n",
    "for word in r_datascience_word_list:\n",
    "    if word in r_datascience_word_dict:\n",
    "        r_datascience_word_dict[word]+=1\n",
    "    else:\n",
    "        r_datascience_word_dict[word]=0\n",
    "        \n",
    "for key in r_datascience_word_dict:\n",
    "    r_datascience_word_dict[key]=1.*r_datascience_word_dict[key]/len(r_datascience_word_list)\n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in se_datascience_word_list:\n",
    "    if word in se_datascience_word_dict:\n",
    "        se_datascience_word_dict[word]+=1\n",
    "    else:\n",
    "        se_datascience_word_dict[word]=0\n",
    "        \n",
    "for key in se_datascience_word_dict:\n",
    "    se_datascience_word_dict[key]=1.*se_datascience_word_dict[key]/len(se_datascience_word_list)\n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in r_statistics_word_list:\n",
    "    if word in r_statistics_word_dict:\n",
    "        r_statistics_word_dict[word]+=1\n",
    "    else:\n",
    "        r_statistics_word_dict[word]=0\n",
    "        \n",
    "for key in r_statistics_word_dict:\n",
    "    r_statistics_word_dict[key]=1.*r_statistics_word_dict[key]/len(r_statistics_word_list)\n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in r_compsci_word_list:\n",
    "    if word in r_compsci_word_dict:\n",
    "        r_compsci_word_dict[word]+=1\n",
    "    else:\n",
    "        r_compsci_word_dict[word]=0\n",
    "        \n",
    "for key in r_compsci_word_dict:\n",
    "    r_compsci_word_dict[key]=1.*r_compsci_word_dict[key]/len(r_compsci_word_list)\n",
    "        \n",
    "################################################################################################################    \n",
    "    \n",
    "for word in se_stackoverflow_word_list:\n",
    "    if word in se_stackoverflow_word_dict:\n",
    "        se_stackoverflow_word_dict[word]+=1\n",
    "    else:\n",
    "        se_stackoverflow_word_dict[word]=0\n",
    "        \n",
    "for key in se_stackoverflow_word_dict:\n",
    "    se_stackoverflow_word_dict[key]=1.*se_stackoverflow_word_dict[key]/len(se_stackoverflow_word_list)   \n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in r_physics_word_list:\n",
    "    if word in r_physics_word_dict:\n",
    "        r_physics_word_dict[word]+=1\n",
    "    else:\n",
    "        r_physics_word_dict[word]=0\n",
    "        \n",
    "for key in r_physics_word_dict:\n",
    "    r_physics_word_dict[key]=1.*r_physics_word_dict[key]/len(r_physics_word_list)\n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in r_Cooking_word_list:\n",
    "    if word in r_Cooking_word_dict:\n",
    "        r_Cooking_word_dict[word]+=1\n",
    "    else:\n",
    "        r_Cooking_word_dict[word]=0\n",
    "        \n",
    "for key in r_Cooking_word_dict:\n",
    "    r_Cooking_word_dict[key]=1.*r_Cooking_word_dict[key]/len(r_Cooking_word_list)\n",
    "    \n",
    "################################################################################################################\n",
    "    \n",
    "for word in r_food_word_list:\n",
    "    if word in r_food_word_dict:\n",
    "        r_food_word_dict[word]+=1\n",
    "    else:\n",
    "        r_food_word_dict[word]=0\n",
    "        \n",
    "for key in r_food_word_dict:\n",
    "    r_food_word_dict[key]=1.*r_food_word_dict[key]/len(r_food_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most common words, plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "def get_top_twenty_terms(dict):\n",
    "    temp_dict=copy(dict)\n",
    "    word_list=['' for i in range(20)]\n",
    "    for i in range(20):\n",
    "        word_list[i]=max(temp_dict, key=temp_dict.get)\n",
    "        temp_dict={key: value for key, value in temp_dict.iteritems() if key!=word_list[i]}\n",
    "    print word_list\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MachineLearning_most_common_words=get_top_twenty_terms(MachineLearning_word_dict)\n",
    "datascience_most_common_words=get_top_twenty_terms(datascience_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "plt.scatter([i for i in range(len(MachineLearning_most_common_words))], [log(MachineLearning_word_dict[key]) for key in MachineLearning_most_common_words],\\\n",
    "           color=MachineLearning_color, label='/r/MachineLearning', s=24)\n",
    "plt.scatter([i for i in range(len(datascience_most_common_words))], [log(datascience_word_dict[key]) for key in datascience_most_common_words],\\\n",
    "                                                                    color=datascience_color, label='/r/datascience', s=24)\n",
    "\n",
    "plt.legend(loc='upper right', prop={'size':legend_size})\n",
    "\n",
    "plt.xlim(-1,len(MachineLearning_most_common_words))\n",
    "#plt.ylim(-.01,0.1)\n",
    "\n",
    "fig.set_size_inches(12,10)\n",
    "plt.title('most common terms in /r/MachineLearning and /r/datascience submissions', size = title_size)\n",
    "plt.xlabel('term', size=label_size)\n",
    "plt.ylabel('log normalized frequency', size=label_size)\n",
    "plt.xticks([])\n",
    "plt.yticks(size=ticklabel_size)\n",
    "\n",
    "\n",
    "xoffset=0.0\n",
    "yoffset=0.0\n",
    "\n",
    "for i in range(len(MachineLearning_most_common_words)):\n",
    "    xoffset1=xoffset\n",
    "    yoffset1=yoffset\n",
    "    xoffset2=-1*xoffset\n",
    "    yoffset2=-1*yoffset\n",
    "    ha1='right'\n",
    "    va1='top'\n",
    "    ha2='left'\n",
    "    va2='bottom'\n",
    "    if MachineLearning_word_dict[MachineLearning_most_common_words[i]] > datascience_word_dict[datascience_most_common_words[i]]:\n",
    "        xoffset1=-1*xoffset\n",
    "        yoffset1=-1*yoffset\n",
    "        xoffset2=xoffset\n",
    "        yoffset2=yoffset\n",
    "        ha1='left'\n",
    "        va1='bottom'\n",
    "        ha2='right'\n",
    "        va2='top'\n",
    "    plt.text(i,\\\n",
    "             log(MachineLearning_word_dict[MachineLearning_most_common_words[i]]), \\\n",
    "             MachineLearning_most_common_words[i], rotation='45', color=MachineLearning_color, ha=ha1, va=va1, size=text_size)\n",
    "    \n",
    "    plt.text(i,\\\n",
    "             log(datascience_word_dict[datascience_most_common_words[i]])+0, \\\n",
    "             datascience_most_common_words[i], rotation='45', color=datascience_color, ha=ha2, va=va2, size=text_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cosine distance between all subreddit dicts, plot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_distance(dict1, dict2):\n",
    "    distance=0\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            distance+=dict1[key]*dict2[key]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_MachineLearning_r_datascience=log(cosine_distance(r_MachineLearning_word_dict, r_datascience_word_dict))\n",
    "r_MachineLearning_se_datascience=log(cosine_distance(r_MachineLearning_word_dict, se_datascience_word_dict))\n",
    "r_MachineLearning_r_statistics=log(cosine_distance(r_MachineLearning_word_dict, r_statistics_word_dict))\n",
    "r_MachineLearning_r_compsci=log(cosine_distance(r_MachineLearning_word_dict, r_compsci_word_dict))\n",
    "r_MachineLearning_se_stackoverflow=log(cosine_distance(r_MachineLearning_word_dict, se_stackoverflow_word_dict))\n",
    "r_MachineLearning_r_physics=log(cosine_distance(r_MachineLearning_word_dict, r_physics_word_dict))\n",
    "r_MachineLearning_r_Cooking=log(cosine_distance(r_MachineLearning_word_dict, r_Cooking_word_dict))\n",
    "r_MachineLearning_r_food=log(cosine_distance(r_MachineLearning_word_dict, r_food_word_dict))\n",
    "\n",
    "r_datascience_se_datascience=log(cosine_distance(r_datascience_word_dict, se_datascience_word_dict))\n",
    "r_datascience_r_statistics=log(cosine_distance(r_datascience_word_dict, r_statistics_word_dict))\n",
    "r_datascience_r_compsci=log(cosine_distance(r_datascience_word_dict, r_compsci_word_dict))\n",
    "r_datascience_se_stackoverflow=log(cosine_distance(r_datascience_word_dict, se_stackoverflow_word_dict))\n",
    "r_datascience_r_physics=log(cosine_distance(r_datascience_word_dict, r_physics_word_dict))\n",
    "r_datascience_r_Cooking=log(cosine_distance(r_datascience_word_dict, r_Cooking_word_dict))\n",
    "r_datascience_r_food=log(cosine_distance(r_datascience_word_dict, r_food_word_dict))\n",
    "\n",
    "se_datascience_r_statistics=log(cosine_distance(se_datascience_word_dict, r_statistics_word_dict))\n",
    "se_datascience_r_compsci=log(cosine_distance(se_datascience_word_dict, r_compsci_word_dict))\n",
    "se_datascience_se_stackoverflow=log(cosine_distance(se_datascience_word_dict, se_stackoverflow_word_dict))\n",
    "se_datascience_r_physics=log(cosine_distance(se_datascience_word_dict, r_physics_word_dict))\n",
    "se_datascience_r_Cooking=log(cosine_distance(se_datascience_word_dict, r_Cooking_word_dict))\n",
    "se_datascience_r_food=log(cosine_distance(se_datascience_word_dict, r_food_word_dict))\n",
    "\n",
    "r_statistics_r_compsci=log(cosine_distance(r_statistics_word_dict, r_compsci_word_dict))\n",
    "r_statistics_se_stackoverflow=log(cosine_distance(r_statistics_word_dict, se_stackoverflow_word_dict))\n",
    "r_statistics_r_physics=log(cosine_distance(r_statistics_word_dict, r_physics_word_dict))\n",
    "r_statistics_r_Cooking=log(cosine_distance(r_statistics_word_dict, r_Cooking_word_dict))\n",
    "r_statistics_r_food=log(cosine_distance(r_statistics_word_dict, r_food_word_dict))\n",
    "\n",
    "r_compsci_se_stackoverflow=log(cosine_distance(r_compsci_word_dict, se_stackoverflow_word_dict))\n",
    "r_compsci_r_physics=log(cosine_distance(r_compsci_word_dict, r_physics_word_dict))\n",
    "r_compsci_r_Cooking=log(cosine_distance(r_compsci_word_dict, r_Cooking_word_dict))\n",
    "r_compsci_r_food=log(cosine_distance(r_compsci_word_dict, r_food_word_dict))\n",
    "\n",
    "se_stackoverflow_r_physics=log(cosine_distance(se_stackoverflow_word_dict, r_physics_word_dict))\n",
    "se_stackoverflow_r_Cooking=log(cosine_distance(se_stackoverflow_word_dict, r_Cooking_word_dict))\n",
    "se_stackoverflow_r_food=log(cosine_distance(se_stackoverflow_word_dict, r_food_word_dict))\n",
    "\n",
    "r_physics_r_Cooking=log(cosine_distance(r_physics_word_dict, r_Cooking_word_dict))\n",
    "r_physics_r_food=log(cosine_distance(r_physics_word_dict, r_food_word_dict))\n",
    "\n",
    "r_Cooking_r_food=log(cosine_distance(r_Cooking_word_dict, r_food_word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. MachineLearning\n",
    "1. datascience\n",
    "2. statistics\n",
    "3. compsci\n",
    "4. physics\n",
    "5. Cooking\n",
    "6. food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine_matrix=np.zeros((9,9))\n",
    "\n",
    "\n",
    "cosine_matrix[0,1]=r_MachineLearning_r_datascience\n",
    "cosine_matrix[1,0]=cosine_matrix[0,1]\n",
    "\n",
    "cosine_matrix[0,2]=r_MachineLearning_se_datascience\n",
    "cosine_matrix[2,0]=cosine_matrix[0,2]\n",
    "\n",
    "cosine_matrix[0,3]=r_MachineLearning_r_statistics\n",
    "cosine_matrix[3,0]=cosine_matrix[0,3]\n",
    "\n",
    "cosine_matrix[0,4]=r_MachineLearning_r_compsci\n",
    "cosine_matrix[4,0]=cosine_matrix[0,4]\n",
    "\n",
    "cosine_matrix[0,5]=r_MachineLearning_se_stackoverflow\n",
    "cosine_matrix[5,0]=cosine_matrix[0,5]\n",
    "\n",
    "cosine_matrix[0,6]=r_MachineLearning_r_physics\n",
    "cosine_matrix[6,0]=cosine_matrix[0,6]\n",
    "\n",
    "cosine_matrix[0,7]=r_MachineLearning_r_Cooking\n",
    "cosine_matrix[7,0]=cosine_matrix[0,7]\n",
    "\n",
    "cosine_matrix[0,8]=r_MachineLearning_r_food\n",
    "cosine_matrix[8,0]=cosine_matrix[0,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[1,2]=r_datascience_se_datascience\n",
    "cosine_matrix[2,1]=cosine_matrix[1,2]\n",
    "\n",
    "cosine_matrix[1,3]=r_datascience_r_statistics\n",
    "cosine_matrix[3,1]=cosine_matrix[1,3]\n",
    "\n",
    "cosine_matrix[1,4]=r_datascience_r_compsci\n",
    "cosine_matrix[4,1]=cosine_matrix[1,4]\n",
    "\n",
    "cosine_matrix[1,5]=r_datascience_se_stackoverflow\n",
    "cosine_matrix[5,1]=cosine_matrix[1,5]\n",
    "\n",
    "cosine_matrix[1,6]=r_datascience_r_physics\n",
    "cosine_matrix[6,1]=cosine_matrix[1,6]\n",
    "\n",
    "cosine_matrix[1,7]=r_datascience_r_Cooking\n",
    "cosine_matrix[7,1]=cosine_matrix[1,7]\n",
    "\n",
    "cosine_matrix[1,8]=r_datascience_r_food\n",
    "cosine_matrix[8,1]=cosine_matrix[1,8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[2,3]=se_datascience_r_statistics\n",
    "cosine_matrix[3,2]=cosine_matrix[2,3]\n",
    "\n",
    "cosine_matrix[2,4]=se_datascience_r_compsci\n",
    "cosine_matrix[4,2]=cosine_matrix[2,4]\n",
    "\n",
    "cosine_matrix[2,5]=se_datascience_se_stackoverflow\n",
    "cosine_matrix[5,2]=cosine_matrix[2,5]\n",
    "\n",
    "cosine_matrix[2,6]=se_datascience_r_physics\n",
    "cosine_matrix[6,2]=cosine_matrix[2,6]\n",
    "\n",
    "cosine_matrix[2,7]=se_datascience_r_Cooking\n",
    "cosine_matrix[7,2]=cosine_matrix[2,7]\n",
    "\n",
    "cosine_matrix[2,8]=se_datascience_r_food\n",
    "cosine_matrix[8,2]=cosine_matrix[2,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[3,4]=r_statistics_r_compsci\n",
    "cosine_matrix[4,3]=cosine_matrix[3,4]\n",
    "\n",
    "cosine_matrix[3,5]=r_statistics_se_stackoverflow\n",
    "cosine_matrix[5,3]=cosine_matrix[3,5]\n",
    "\n",
    "cosine_matrix[3,6]=r_statistics_r_physics\n",
    "cosine_matrix[6,3]=cosine_matrix[3,6]\n",
    "\n",
    "cosine_matrix[3,7]=r_statistics_r_Cooking\n",
    "cosine_matrix[7,3]=cosine_matrix[3,7]\n",
    "\n",
    "cosine_matrix[3,8]=r_statistics_r_food\n",
    "cosine_matrix[8,3]=cosine_matrix[3,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[4,5]=r_compsci_se_stackoverflow\n",
    "cosine_matrix[5,4]=cosine_matrix[4,5]\n",
    "\n",
    "cosine_matrix[4,6]=r_compsci_r_physics\n",
    "cosine_matrix[6,4]=cosine_matrix[4,6]\n",
    "\n",
    "cosine_matrix[4,7]=r_compsci_r_Cooking\n",
    "cosine_matrix[7,4]=cosine_matrix[4,7]\n",
    "\n",
    "cosine_matrix[4,8]=r_compsci_r_food\n",
    "cosine_matrix[8,4]=cosine_matrix[4,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[5,6]=se_stackoverflow_r_physics\n",
    "cosine_matrix[6,5]=cosine_matrix[5,6]\n",
    "\n",
    "cosine_matrix[5,7]=se_stackoverflow_r_Cooking\n",
    "cosine_matrix[7,5]=cosine_matrix[5,7]\n",
    "\n",
    "cosine_matrix[5,8]=se_stackoverflow_r_food\n",
    "cosine_matrix[8,5]=cosine_matrix[5,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[6,7]=r_physics_r_Cooking\n",
    "cosine_matrix[7,6]=cosine_matrix[6,7]\n",
    "\n",
    "cosine_matrix[6,8]=r_physics_r_food\n",
    "cosine_matrix[8,6]=cosine_matrix[6,8]\n",
    "\n",
    "\n",
    "\n",
    "cosine_matrix[7,8]=r_Cooking_r_food\n",
    "cosine_matrix[8,7]=cosine_matrix[7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cmap\n",
    "fig=plt.figure()\n",
    "cmap=cmap.gray\n",
    "im=plt.imshow(cosine_matrix, interpolation='none', vmin=-8.5, vmax=-5.5, cmap=cmap)\n",
    "\n",
    "plt.xlim(-0.5,8.5)\n",
    "plt.ylim(-0.5,8.5)\n",
    "\n",
    "plt.title('submissions log cosine similarity', size=title_size)\n",
    "for i in range(0, 9):\n",
    "    plt.plot([i+.5,i+.5],[-10,10], color=(1,1,1))\n",
    "    plt.plot([-10,10],[i+.5,i+.5], color=(1,1,1))\n",
    "    \n",
    "plt.gca().xaxis.grid(False)\n",
    "plt.gca().yaxis.grid(False)\n",
    "\n",
    "plt.xticks([0,1,2, 3, 4, 5, 6, 7, 8],\\\n",
    "           ['/r/Machine\\nLearning', '/r/datascience', 'stackexchange.\\ndatascience', '/r/statistics',\\\n",
    "            '/r/compsci', 'stackoverflow', '/r/physics', '/r/Cooking', '/r/food'], rotation='15', font_properties='bold')\n",
    "plt.yticks([0,1,2, 3, 4, 5, 6, 7, 8],\\\n",
    "           ['/r/Machine\\nLearning', '/r/datascience', 'stackexchange.\\ndatascience', '/r/statistics',\\\n",
    "            '/r/compsci', 'stackoverflow', '/r/physics', '/r/Cooking', '/r/food'], font_properties='bold')\n",
    "\n",
    "for i in range(0,9):\n",
    "    for j in range(i,9):\n",
    "        plt.text(j-.5+.1, i-.5+.1, str(round(cosine_matrix[i,j],3)), color=(1.,0,0), ha='left', va='bottom', size=14,\\\n",
    "                font_properties='bold')\n",
    "\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine distance between search and subreddit dict for different search terms and subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_distance(search, dict1):\n",
    "    distance=0\n",
    "    num_words=len(search.split(' '))\n",
    "    for word in search.split(' '):\n",
    "        if word in dict1:\n",
    "            distance+=1.*dict1[word]/num_words\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searches=['machine learning', 'data science', 'big data', 'python r', 'regression', 'classification', 'neural network']\n",
    "r_MachineLearning_distance={term: 0 for term in searches}\n",
    "r_datascience_distance={term: 0 for term in searches}\n",
    "se_datascience_distance={term: 0 for term in searches}\n",
    "for search in searches:\n",
    "    r_MachineLearning_distance[search]=cosine_distance(search, r_MachineLearning_word_dict)\n",
    "    r_datascience_distance[search]=cosine_distance(search, r_datascience_word_dict)\n",
    "    se_datascience_distance[search]=cosine_distance(search, se_datascience_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.bar([4*i for i in range(len(searches))], [r_MachineLearning_distance[searches[i]] for i in range(len(searches))],\\\n",
    "        alpha=0.75, color = MachineLearning_color, label='/r/MachineLearning')\n",
    "plt.bar([4*i+2*ra.random()-1. for i in range(len(searches))], [r_datascience_distance[searches[i]] for i in range(len(searches))],\\\n",
    "        alpha=0.75, color = datascience_color, label='/r/datascience')\n",
    "plt.bar([4*i+2*ra.random()-1. for i in range(len(searches))], [se_datascience_distance[searches[i]] for i in range(len(searches))],\\\n",
    "        alpha=0.75, color = (106/255., 204/255., 101/255.), label='datascience.stackexchange')\n",
    "\n",
    "plt.legend(prop={'size': legend_size})\n",
    "plt.xlim(-2, (4*len(searches)-1))\n",
    "    \n",
    "fig.set_size_inches(12,10)\n",
    "plt.title('cosine similarity of search phrase and community submissions vector', size=title_size)\n",
    "plt.xlabel('search terms', size=label_size)\n",
    "plt.ylabel('normalized cosine distance', size=label_size)\n",
    "\n",
    "plt.xticks([4*i+0.5 for i in range(len(searches))], ['\\''+'\\n'.join(search.split( ))+'\\'' for search in searches], size = ticklabel_size)\n",
    "plt.yticks(size=ticklabel_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blog_list=[]\n",
    "for link in MachineLearning_df['link'].values:\n",
    "    if 'blog' in link:\n",
    "        blog_list.append(link)\n",
    "\n",
    "print len(blog_list)\n",
    "        \n",
    "for blog in blog_list:\n",
    "    print blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sort links by popularity (upvotes with respect to  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
